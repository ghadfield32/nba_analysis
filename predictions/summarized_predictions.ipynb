{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common columns for merge: {'MATCHUP_ID', 'Date', 'TEAM_NAME'}\n",
      "Rows after tree and non-tree merge: 260\n",
      "Rows after adding ltsm_seq data: 260\n",
      "Rows after adding ltsm data: 260\n",
      "Rows after merging with votes data: 260\n",
      "Index(['Date', 'MATCHUP_ID', 'TEAM_NAME', 'XGBoost_PREDICTION',\n",
      "       'Decision Tree_PREDICTION', 'Random Forest_PREDICTION',\n",
      "       'Gradient Boosting_PREDICTION', 'AdaBoost_PREDICTION',\n",
      "       'MLP Classifier_PREDICTION', 'K-Neighbors Classifier_PREDICTION',\n",
      "       'SVM_PREDICTION', 'SGD Classifier_PREDICTION',\n",
      "       'Ridge Classifier_PREDICTION', 'Logistic Regression_PREDICTION',\n",
      "       'ltsm_PREDICTION', 'ltsm_seq_PREDICTION',\n",
      "       'linreg_team_point_PREDICTION', 'TEAM_ID', 'linreg_wl_PREDICTION',\n",
      "       'voter_predictions'],\n",
      "      dtype='object')\n",
      "Final data shape: (260, 115)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# File paths and feature names\n",
    "tree_pred_path = r'C:\\Users\\ghadf\\OneDrive\\Desktop\\Data Analytics\\Python\\ML\\nba_w_l_prediction_models\\nba_analysis\\data\\tree_season_pred.csv'\n",
    "non_tree_pred_path = r'C:\\Users\\ghadf\\OneDrive\\Desktop\\Data Analytics\\Python\\ML\\nba_w_l_prediction_models\\nba_analysis\\data\\non_tree_season_pred.csv'\n",
    "ltsm_pred_path = r'C:\\Users\\ghadf\\OneDrive\\Desktop\\Data Analytics\\Python\\ML\\nba_w_l_prediction_models\\nba_analysis\\data\\ltsm_season_pred.csv'\n",
    "ltsm_seq_pred_path = r'C:\\Users\\ghadf\\OneDrive\\Desktop\\Data Analytics\\Python\\ML\\nba_w_l_prediction_models\\nba_analysis\\data\\ltsm_seq_season_pred.csv'\n",
    "past_results_path = r'C:\\Users\\ghadf\\OneDrive\\Desktop\\Data Analytics\\Python\\ML\\nba_w_l_prediction_models\\nba_analysis\\data\\23_24_current_season_prediction_tracker.csv'\n",
    "votes_data_path = r'C:\\Users\\ghadf\\OneDrive\\Desktop\\Data Analytics\\Python\\ML\\nba_w_l_prediction_models\\nba_analysis\\data\\voter_pred.csv'\n",
    "linreg_team_data_path = r'C:\\Users\\ghadf\\OneDrive\\Desktop\\Data Analytics\\Python\\ML\\nba_w_l_prediction_models\\nba_analysis\\data\\linreg_team_point_pred.csv'\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Take out predictions with the Same value for model so we only track valuable predictions\n",
    "def validate_predictions(data):\n",
    "    prediction_columns = [\n",
    "        'XGBoost_PREDICTION', 'Decision Tree_PREDICTION', 'Random Forest_PREDICTION', \n",
    "        'Gradient Boosting_PREDICTION', 'AdaBoost_PREDICTION', 'MLP Classifier_PREDICTION', \n",
    "        'K-Neighbors Classifier_PREDICTION', 'SVM_PREDICTION', 'SGD Classifier_PREDICTION', \n",
    "        'Ridge Classifier_PREDICTION', 'Logistic Regression_PREDICTION', 'ltsm_PREDICTION', 'ltsm_seq_PREDICTION'\n",
    "    ]\n",
    "    \n",
    "    # Iterate over each prediction column to validate\n",
    "    for col in prediction_columns:\n",
    "        # Calculate the sum of predictions for each matchup within the column\n",
    "        data[f'{col}_sum'] = data.groupby(['Date', 'MATCHUP_ID'])[col].transform('sum')\n",
    "        \n",
    "        # Identify rows where the sum of predictions is not equal to 1\n",
    "        invalid_mask = data[f'{col}_sum'] != 1\n",
    "        \n",
    "        # Set predictions to NaN for rows where the sum is not 1\n",
    "        data.loc[invalid_mask, col] = np.nan\n",
    "    \n",
    "    # Drop the temporary sum columns\n",
    "    sum_columns = [f'{col}_sum' for col in prediction_columns]\n",
    "    data = data.drop(columns=sum_columns)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def load_linreg_team_data(path):\n",
    "    return pd.read_csv(path)\n",
    "\n",
    "\n",
    "# Data Loading Functions\n",
    "def load_tree_data(path):\n",
    "    return pd.read_csv(path)[['Date', 'MATCHUP_ID', 'TEAM_NAME', 'XGBoost_PREDICTION', 'Decision Tree_PREDICTION', 'Random Forest_PREDICTION', 'Gradient Boosting_PREDICTION', 'AdaBoost_PREDICTION']]\n",
    "\n",
    "def load_non_tree_data(path):\n",
    "    return pd.read_csv(path)[['Date', 'MATCHUP_ID', 'TEAM_NAME', 'MLP Classifier_PREDICTION', 'K-Neighbors Classifier_PREDICTION', 'SVM_PREDICTION', 'SGD Classifier_PREDICTION', 'Ridge Classifier_PREDICTION', 'Logistic Regression_PREDICTION']]\n",
    "\n",
    "def load_ltsm_data(path):\n",
    "    ltsm_data = pd.read_csv(path)\n",
    "    ltsm_data = ltsm_data.rename(columns={'PREDICTION': 'ltsm_PREDICTION'})\n",
    "    ltsm_data['Date'] = pd.to_datetime(ltsm_data['Date'])\n",
    "    ltsm_data['Date'] = ltsm_data['Date'].dt.strftime('%Y-%m-%d')\n",
    "    return ltsm_data[['Date', 'MATCHUP_ID', 'TEAM_NAME', 'ltsm_PREDICTION']]\n",
    "\n",
    "def load_ltsm_seq_data(path):\n",
    "    ltsm_seq_data = pd.read_csv(path)\n",
    "    ltsm_seq_data = ltsm_seq_data.rename(columns={'PREDICTION': 'ltsm_seq_PREDICTION'})\n",
    "    return ltsm_seq_data[['Date', 'MATCHUP_ID', 'TEAM_NAME', 'ltsm_seq_PREDICTION']]\n",
    "\n",
    "def load_past_results(path):\n",
    "    return pd.read_csv(path)\n",
    "\n",
    "def merge_data(tree_data, non_tree_data, ltsm_seq_data, ltsm_data):\n",
    "    # Check column names\n",
    "    tree_cols = set(tree_data.columns)\n",
    "    non_tree_cols = set(non_tree_data.columns)\n",
    "    ltsm_seq_cols = set(ltsm_seq_data.columns)\n",
    "    ltsm_cols = set(ltsm_data.columns)\n",
    "    common_cols = tree_cols & non_tree_cols & ltsm_seq_cols & ltsm_cols\n",
    "    print(f\"Common columns for merge: {common_cols}\")\n",
    "    \n",
    "    # Check for matching data types\n",
    "    for col in common_cols:\n",
    "        if tree_data[col].dtype != non_tree_data[col].dtype or \\\n",
    "           tree_data[col].dtype != ltsm_seq_data[col].dtype or \\\n",
    "           tree_data[col].dtype != ltsm_data[col].dtype:\n",
    "            print(f\"Data type mismatch found in column: {col}\")\n",
    "    \n",
    "    # Perform the merges and check row counts\n",
    "    tree_non_tree = pd.merge(tree_data, non_tree_data, on=list(common_cols), how='left')\n",
    "    print(f\"Rows after tree and non-tree merge: {tree_non_tree.shape[0]}\")\n",
    "    \n",
    "    tree_non_tree_ltsm_seq = pd.merge(tree_non_tree, ltsm_seq_data, on=list(common_cols), how='left')\n",
    "    print(f\"Rows after adding ltsm_seq data: {tree_non_tree_ltsm_seq.shape[0]}\")\n",
    "    \n",
    "    all_data = pd.merge(tree_non_tree_ltsm_seq, ltsm_data, on=list(common_cols), how='left')\n",
    "    print(f\"Rows after adding ltsm data: {all_data.shape[0]}\")\n",
    "\n",
    "    # Correct the renaming for linreg_team_data_home\n",
    "    linreg_team_data_home = linreg_team_data[['PTS_HOME', 'TEAM_NAME_HOME', 'TEAM_ID_HOME', 'MATCHUP_ID', 'Date', 'HOME_WIN']]\n",
    "    linreg_team_data_home = linreg_team_data_home.rename(columns={\n",
    "        'PTS_HOME': 'linreg_team_point_PREDICTION', \n",
    "        'TEAM_NAME_HOME': 'TEAM_NAME', \n",
    "        'TEAM_ID_HOME': 'TEAM_ID', \n",
    "        'HOME_WIN': 'linreg_wl_PREDICTION'\n",
    "    })\n",
    "\n",
    "    # Correct the merging operation\n",
    "    #all_data_lr = pd.merge(all_data, linreg_team_data_home, on=list(common_cols), how='left')\n",
    "\n",
    "    # Correct the renaming for linreg_team_data_away\n",
    "    linreg_team_data_away = linreg_team_data[['PTS_AWAY', 'TEAM_NAME_AWAY', 'TEAM_ID_AWAY', 'MATCHUP_ID', 'Date', 'AWAY_WIN']]\n",
    "    linreg_team_data_away = linreg_team_data_away.rename(columns={\n",
    "        'PTS_AWAY': 'linreg_team_point_PREDICTION', \n",
    "        'TEAM_NAME_AWAY': 'TEAM_NAME', \n",
    "        'TEAM_ID_AWAY': 'TEAM_ID', \n",
    "        'AWAY_WIN': 'linreg_wl_PREDICTION'\n",
    "    })\n",
    "\n",
    "    #concatenate the two dataframes\n",
    "    linreg_team_data_union = pd.concat([linreg_team_data_home, linreg_team_data_away])\n",
    "\n",
    "    # Correct the merging operation\n",
    "    all_data_lr_two = pd.merge(all_data, linreg_team_data_union, on=list(common_cols), how='left')\n",
    "\n",
    "\n",
    "\n",
    "    # Check for NaN values in key columns\n",
    "    for col in common_cols:\n",
    "        nan_count = all_data_lr_two[col].isna().sum()\n",
    "        if nan_count > 0:\n",
    "            print(f\"NaN values found in column: {col} - {nan_count} NaNs\")\n",
    "    \n",
    "    # Validate predictions before merging with votes\n",
    "    validated_data = validate_predictions(all_data_lr_two)\n",
    "    \n",
    "    # Now merge with votes data and check final row count\n",
    "    all_data_with_votes = pd.merge(validated_data, aggregated_votes, on=list(common_cols), how='left')\n",
    "    print(f\"Rows after merging with votes data: {all_data_with_votes.shape[0]}\")\n",
    "    \n",
    "    return all_data_with_votes\n",
    "\n",
    "\n",
    "votes_data = pd.read_csv(votes_data_path)\n",
    "# Aggregate votes by Date, MATCHUP_ID, and TEAM_NAME\n",
    "aggregated_votes = votes_data.groupby(['Date', 'MATCHUP_ID', 'TEAM_NAME']).sum().reset_index().rename(columns={'Votes': 'voter_predictions'})\n",
    "\n",
    "tree_data = load_tree_data(tree_pred_path)\n",
    "non_tree_data = load_non_tree_data(non_tree_pred_path)\n",
    "ltsm_data = load_ltsm_data(ltsm_pred_path)\n",
    "ltsm_seq_data = load_ltsm_seq_data(ltsm_seq_pred_path)\n",
    "linreg_team_data = load_linreg_team_data(linreg_team_data_path)\n",
    "\n",
    "# Merge all data\n",
    "all_data = merge_data(tree_data, non_tree_data, ltsm_data, ltsm_seq_data)\n",
    "print(all_data.columns)\n",
    "\n",
    "#merge with past results\n",
    "past_results = load_past_results(past_results_path)\n",
    "#rename GAME_DATE to Date\n",
    "past_results = past_results.rename(columns={'GAME_DATE': 'Date'})\n",
    "all_data = pd.merge(all_data, past_results, on=['Date', 'MATCHUP_ID', 'TEAM_NAME'], how='left')\n",
    "\n",
    "print(f\"Final data shape: {all_data.shape}\")\n",
    "#print(all_data.isna().sum())\n",
    "#print(all_data.head())\n",
    "#print(all_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Date MATCHUP_ID  Correct    PTS  linreg_team_point_PREDICTION  \\\n",
      "0    2023-10-25     SACUTA        0  114.0                           NaN   \n",
      "22   2023-10-25     ATLCHA        0  110.0                           NaN   \n",
      "21   2023-10-25     DETMIA        0  103.0                           NaN   \n",
      "20   2023-10-25     BKNCLE        0  114.0                           NaN   \n",
      "19   2023-10-25     BKNCLE        0  113.0                           NaN   \n",
      "..          ...        ...      ...    ...                           ...   \n",
      "252  2023-11-11     MILORL        0    NaN                    112.145569   \n",
      "253  2023-11-11     MILORL        0    NaN                    118.962616   \n",
      "254  2023-11-11     CLEGSW        0    NaN                    105.463081   \n",
      "255  2023-11-11     CLEGSW        0    NaN                    100.495071   \n",
      "259  2023-11-11     ATLMIA        0    NaN                    108.851364   \n",
      "\n",
      "     Cumulative_MAE  Cumulative_Correct_Percentage  \n",
      "0               NaN                            NaN  \n",
      "22              NaN                            NaN  \n",
      "21              NaN                            NaN  \n",
      "20              NaN                            NaN  \n",
      "19              NaN                            NaN  \n",
      "..              ...                            ...  \n",
      "252       11.064757                       0.363636  \n",
      "253       11.064757                       0.347826  \n",
      "254       11.064757                       0.333333  \n",
      "255       11.064757                       0.320000  \n",
      "259       11.064757                       0.307692  \n",
      "\n",
      "[260 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "all_data.sort_values(by='Date', inplace=True)\n",
    "\n",
    "# Assuming 'WL_encoded' and 'linreg_wl_PREDICTION' are your actual columns that you're comparing.\n",
    "# Only consider rows where 'linreg_wl_PREDICTION' is not null for calculating correctness\n",
    "mask = all_data['linreg_wl_PREDICTION'].notnull()\n",
    "all_data.loc[mask, 'Correct'] = np.where(all_data.loc[mask, 'WL_encoded'] == all_data.loc[mask, 'linreg_wl_PREDICTION'], 1, 0)\n",
    "\n",
    "# Calculate the point differences only where 'linreg_team_point_PREDICTION' is not null\n",
    "mask = all_data['linreg_team_point_PREDICTION'].notnull()\n",
    "all_data.loc[mask, 'Point_Diff'] = abs(all_data.loc[mask, 'PTS'] - all_data.loc[mask, 'linreg_team_point_PREDICTION'])\n",
    "\n",
    "# Calculate the cumulative MAE only on non-null Point_Diff values\n",
    "all_data['Cumulative_MAE'] = all_data.loc[mask, 'Point_Diff'].expanding().mean()\n",
    "\n",
    "# Calculate the cumulative correct sum only on non-null Correct values\n",
    "all_data['Cumulative_Correct'] = all_data.loc[mask, 'Correct'].expanding().sum()\n",
    "\n",
    "# Games predicted would also be the cumulative count of non-null predictions\n",
    "all_data['Games_Predicted'] = all_data.loc[mask, 'Correct'].expanding().count()\n",
    "\n",
    "# Calculate the cumulative correct percentage\n",
    "all_data['Cumulative_Correct_Percentage'] = all_data['Cumulative_Correct'] / all_data['Games_Predicted']\n",
    "\n",
    "# Print the relevant data\n",
    "print(all_data[['Date', 'MATCHUP_ID', 'Correct', 'PTS', 'linreg_team_point_PREDICTION', 'Cumulative_MAE', 'Cumulative_Correct_Percentage']])\n",
    "\n",
    "# Optionally, save to CSV\n",
    "# all_data.to_csv('updated_predictions_tracker.csv', index=False)\n",
    "#^^do this for all _prediction columns and then just display the last row in the app and the accuracy columns for the scatterplot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
